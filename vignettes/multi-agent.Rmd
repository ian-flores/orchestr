---
title: "Multi-Agent Workflows"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Multi-Agent Workflows}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

## Choosing a Multi-Agent Pattern

When a single agent is not enough -- because the task has distinct stages, or
because different subtasks require different expertise -- orchestr provides two
multi-agent patterns: **pipelines** and **supervisors**. Choosing between them
is the first design decision for any multi-agent workflow.

A **pipeline** is the right choice when you know the sequence of steps at
design time. Data flows linearly from one specialist to the next, like an
assembly line. Each agent makes exactly one LLM call, so costs are
predictable and execution order is deterministic.

A **supervisor** is the right choice when the routing depends on the content
of the request. A coordinator agent reads the user's message, decides which
specialist should handle it, and dispatches accordingly. The supervisor can
route to multiple workers across several iterations, making it suitable for
open-ended tasks where the needed expertise is not known in advance.

Here is a comparison of the two patterns:

```
 Pattern     | Flow          | LLM Calls  | Best For
 ------------|---------------|------------|----------------------------------
 Pipeline    | A -> B -> C   | 1 per node | Fixed stages, predictable cost
 Supervisor  | Router -> *   | 2+ per     | Dynamic routing, open-ended tasks
             |               | iteration  |
```

If your workflow has a fixed sequence of steps, start with a pipeline. If the
routing logic depends on the user's input, use a supervisor. If you need
something more complex (conditional branches, cycles, human-in-the-loop
approvals), drop down to `graph_builder()` for full control over the topology.

## Pipeline Pattern

A pipeline passes state through a sequence of agents, each transforming
it before handing off to the next. The key idea is **separation of concerns**:
each agent has a focused role, and the pipeline composes them into a coherent
workflow. This makes individual agents easier to test, swap, and reason about
compared to a single monolithic prompt.

The pipeline flow looks like this:

```
 [User Input]
      |
      v
 +-----------+     +-----------+     +-----------+
 |  Agent A  | --> |  Agent B  | --> |  Agent C  |
 | (profile) |     | (analyze) |     |  (report) |
 +-----------+     +-----------+     +-----------+
                                          |
                                          v
                                    [Final Output]
```

Use `pipeline_graph()` for a concise setup, or `graph_builder()` for full
control.

### Using `pipeline_graph()`

The simplest way to create a pipeline. Pass agents in order and orchestr
wires the edges automatically.

```{r pipeline-convenience}
library(orchestr)
library(ellmer)

drafter <- agent("drafter", chat = chat_anthropic(
  system_prompt = "Write a short draft on the given topic."
))

editor <- agent("editor", chat = chat_anthropic(
  system_prompt = "Improve the following draft. Fix grammar and clarity."
))

pipeline <- pipeline_graph(drafter, editor)

result <- pipeline$invoke(list(
  messages = list("Write about the benefits of open source software.")
))
cat(result$messages[[length(result$messages)]])
```

### Data Analysis Pipeline

A more realistic pipeline that profiles data, analyzes patterns, and
produces a report. This three-stage design is common in data science
workflows: the profiler gathers facts, the analyst finds meaning, and
the reporter communicates results. Each agent sees the accumulated
conversation history, so the analyst can reference the profiler's output
and the reporter can reference both.

```{r pipeline-data}
profiler <- agent("profiler", chat = chat_anthropic(
  system_prompt = "Profile datasets: describe columns, types, missing values, distributions."
))

analyst <- agent("analyst", chat = chat_anthropic(
  system_prompt = "Given a data profile, identify patterns, correlations, and anomalies."
))

reporter <- agent("reporter", chat = chat_anthropic(
  system_prompt = "Write a clear, non-technical summary of analytical findings."
))

graph <- pipeline_graph(profiler, analyst, reporter)
result <- graph$invoke(list(messages = list(
  "Analyze the mtcars dataset focusing on fuel efficiency factors."
)))
```

### Using `graph_builder()` Directly

For more control -- conditional edges, cycles, or custom node functions --
use the builder API. This is the same API that `pipeline_graph()` and
`supervisor_graph()` use internally. The builder gives you full access to
the graph topology: add nodes, wire edges (including conditional edges),
and set the entry point explicitly.

```{r pipeline-builder}
drafter <- agent("drafter", chat = chat_anthropic(
  system_prompt = "Write a short draft on the given topic."
))

editor <- agent("editor", chat = chat_anthropic(
  system_prompt = "Improve the following draft. Fix grammar and clarity."
))

g <- graph_builder()
g$add_node("draft", drafter)
g$add_node("edit", editor)
g$add_edge("draft", "edit")
g$add_edge("edit", END)
g$set_entry_point("draft")

pipeline <- g$compile(verbose = TRUE)

result <- pipeline$invoke(list(
  messages = list("Write about functional programming in R.")
))
cat(result$messages[[length(result$messages)]])
```

## Supervisor Pattern

While pipelines follow a fixed path, supervisors make **dynamic routing
decisions** at runtime. A supervisor agent receives the user's request,
evaluates which specialist is best suited to handle it, and dispatches the
work using a `route` tool that orchestr injects automatically. After the
worker responds, control returns to the supervisor, which can route again
(to a different worker, or the same one) or finish.

This pattern is powerful for open-ended tasks where the required expertise
depends on the input. A question about calculus goes to the math worker;
a request to polish prose goes to the writing worker. The supervisor makes
this decision using the LLM's own judgment, guided by its system prompt
and the worker descriptions.

The routing flow looks like this:

```
                 +------------+
                 | Supervisor |
                 +-----+------+
                       |
          route("math") | route("writing") | FINISH
               |                |               |
               v                v               v
          +--------+      +----------+      [Output]
          |  Math  |      | Writing  |
          +--------+      +----------+
               |                |
               +----+     +----+
                    |     |
                    v     v
               (back to Supervisor)
```

```{r supervisor}
supervisor <- agent("supervisor", chat = chat_anthropic(
  system_prompt = "You coordinate workers to solve tasks."
))

math_worker <- agent("math", chat = chat_anthropic(
  system_prompt = "You are a math expert. Solve math problems step by step."
))

writing_worker <- agent("writing", chat = chat_anthropic(
  system_prompt = "You are a writing expert. Help with writing tasks."
))

graph <- supervisor_graph(
  supervisor = supervisor,
  workers = list(math = math_worker, writing = writing_worker),
  max_iterations = 10
)

# Route to math
result <- graph$invoke(list(
  messages = list("Calculate the integral of x^2 from 0 to 1.")
))
```

The supervisor automatically receives a `route` tool that it calls to
dispatch to workers or finish. Start with low `max_iterations` values to
control costs -- each iteration involves an LLM call for the supervisor
plus the selected worker.

## State Management

All graph types in orchestr share a common state model. State is a named
list that flows through the graph, getting modified by each node. By default,
orchestr uses a simple schema where `messages` is a list that gets appended
to as agents respond.

Understanding state flow matters because it determines what each agent sees.
In a pipeline, the second agent sees the first agent's output in the message
history. In a supervisor, each worker sees the full conversation including
the supervisor's routing decisions. This shared-state design means agents
can build on each other's work without explicit message passing.

For advanced use cases, `StateSchema$new()` lets you define typed fields
with custom reducers. For example, you might accumulate a `findings` list
across pipeline stages while keeping a `summary` field that gets overwritten
by the final agent.

## Streaming State Snapshots

Use `$stream()` to collect state snapshots at each step. This is useful for
building progress indicators in interactive applications, or for debugging
graph execution by inspecting intermediate states.

```{r stream}
pipeline <- pipeline_graph(
  agent("drafter", chat = chat_anthropic(
    system_prompt = "Write a short draft on the given topic."
  )),
  agent("editor", chat = chat_anthropic(
    system_prompt = "Improve the following draft."
  ))
)

snapshots <- pipeline$stream(list(
  messages = list("Write about functional programming in R.")
))

for (snap in snapshots) {
  cat(sprintf("Step %d, node: %s\n", snap$step, snap$node))
}
```

## Visualizing the Graph

Understanding the topology of a graph is easier with a visual
representation. `as_mermaid()` generates a Mermaid diagram string that
you can render in any Mermaid-compatible viewer (GitHub markdown, pkgdown
sites, Quarto documents, or the Mermaid live editor).

```{r mermaid}
supervisor <- agent("supervisor", chat = chat_anthropic(
  system_prompt = "You coordinate workers."
))
math_worker <- agent("math", chat = chat_anthropic(
  system_prompt = "Math expert."
))
writing_worker <- agent("writing", chat = chat_anthropic(
  system_prompt = "Writing expert."
))

graph <- supervisor_graph(
  supervisor = supervisor,
  workers = list(math = math_worker, writing = writing_worker)
)

cat(as_mermaid(graph))
# Output:
# graph TD
#     supervisor[supervisor]
#     math[math]
#     writing[writing]
#     supervisor -->|math| math
#     supervisor -->|writing| writing
#     math --> supervisor
#     writing --> supervisor
```

## Next Steps

- **[Getting Started](quickstart.html)** -- single-agent basics and provider setup
- **[Secure Execution](securer.html)** -- sandboxed code execution with securer
- **[Traced Workflows](tracing.html)** -- observability with securetrace
- **[Governed Agent](governed-agent.html)** -- the full 7-package stack
