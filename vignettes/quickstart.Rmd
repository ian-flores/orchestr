---
title: "Getting Started with orchestr"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting Started with orchestr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

## What Problem Does orchestr Solve?

Large language models are remarkably capable on their own, but building a
production-grade AI agent requires more than a single prompt-response exchange.
You need structured reasoning loops so the model can think before it acts.
You need pipelines that chain specialists together. You need supervisors that
route work to the right expert. And you need all of this to be observable,
checkpointable, and safe.

orchestr provides a **graph-based orchestration layer** for R that sits on top
of [ellmer](https://github.com/tidyverse/ellmer) (the LLM chat interface) and
optionally [securer](https://github.com/ian-flores/securer) (sandboxed code
execution). Instead of writing ad-hoc loops and if-else routing, you define
agents, wire them into a graph, and let orchestr handle execution flow,
state management, and iteration control.

The core abstraction is simple: **agents are nodes, edges define flow, and
the graph runtime handles the rest**. Whether you need a single ReAct agent,
a three-stage pipeline, or a supervisor that dynamically routes to a pool
of workers, the same graph primitives apply.

### The ReAct Pattern

orchestr's default execution model follows the ReAct (Reasoning + Acting)
pattern. The agent repeatedly thinks about what to do, takes an action
(typically a tool call), observes the result, and decides whether to continue
or stop:

```
 think --> act --> observe
   ^                  |
   |                  |
   +------ loop ------+
         (until done or max iterations)
```

This loop is implemented by `react_graph()` and runs within a safety cap
(`max_iterations`) to prevent runaway LLM calls.

### When to Use orchestr vs. Plain ellmer

If your use case is a single prompt-response exchange -- ask a question, get an
answer -- plain ellmer is the right choice. ellmer handles tool call loops
internally, supports streaming, and has minimal overhead.

Reach for orchestr when you need one or more of:

- **Multi-agent workflows** -- pipelines, supervisors, or custom graph topologies
- **State management** -- typed state schemas with reducers that accumulate
  results across nodes
- **Checkpointing** -- save and resume graph execution mid-run
- **Observability** -- automatic span creation when combined with securetrace
- **Iteration control** -- max_iterations caps, conditional routing, interrupt
  and approval flows

In short: ellmer gives you a single agent with tools; orchestr gives you a
framework for composing multiple agents into governed workflows.

## Installation

```r
install.packages("orchestr")
```

## API Key Setup

orchestr uses [ellmer](https://github.com/tidyverse/ellmer) for LLM access.
Set your provider's API key before running any examples:

```{r api-key}
# For Anthropic (Claude)
Sys.setenv(ANTHROPIC_API_KEY = "your-key-here")

# For OpenAI
Sys.setenv(OPENAI_API_KEY = "your-key-here")
```

See ellmer's documentation for all supported providers.

## Using Different Providers

orchestr works with any ellmer chat backend. This is a deliberate design
choice: the orchestration layer should not care which LLM you use. Pass
the appropriate `chat_*()` constructor to `agent()` and everything --
graphs, pipelines, supervisors, tracing -- works identically regardless
of the backing model.

```{r providers}
library(orchestr)
library(ellmer)

# OpenAI
agent("analyst", chat = chat_openai(model = "gpt-4o"))

# Google Gemini
agent("analyst", chat = chat_google_gemini(model = "gemini-1.5-pro"))

# Claude via AWS Bedrock
agent("analyst", chat = chat_aws_bedrock(
  model = "anthropic.claude-3-5-sonnet-20241022-v2:0"
))

# GPT-4o via Azure OpenAI
agent("analyst", chat = chat_azure_openai(
  endpoint = "https://my-resource.openai.azure.com",
  deployment_id = "gpt-4o"
))
```

All graph types (`react_graph()`, `pipeline_graph()`, `supervisor_graph()`)
work identically regardless of which provider backs the agent.

## Your First Agent

An `Agent` wraps an ellmer `Chat` object with a name and an optional system
prompt. The `agent()` constructor is the recommended entry point because
it validates inputs and provides sensible defaults. Under the hood, it creates
an R6 `Agent` instance that manages conversation state and tool registration.

```{r single-agent}
library(orchestr)
library(ellmer)

analyst <- agent("analyst", chat = chat_anthropic(
  system_prompt = "You are a data analyst. Analyze data and provide insights."
))

# Single-turn conversation
response <- analyst$invoke("Describe the key features of the iris dataset.")
cat(response)
```

## Adding Tools

Agents become truly useful when they can take actions beyond generating text.
Tools let an agent call R functions -- looking up data, running calculations,
querying databases -- as part of its reasoning process. ellmer's `Chat` class
handles tool call loops internally: when the model decides to use a tool,
ellmer executes the function and feeds the result back automatically.

This matters because it transforms the agent from a text generator into an
actor that can observe real data and adapt its analysis accordingly.

```{r tools}
summary_tool <- tool(
  function(dataset_name) {
    data <- get(dataset_name, envir = asNamespace("datasets"))
    paste(capture.output(summary(data)), collapse = "\n")
  },
  "Get a summary of a built-in R dataset.",
  arguments = list(
    dataset_name = type_string("Name of a dataset in the datasets package")
  )
)

analyst <- agent("analyst",
  chat = chat_anthropic(
    system_prompt = "You are a data analyst. Use your tools to examine data."
  ),
  tools = list(summary_tool)
)

response <- analyst$invoke("Summarize the mtcars dataset.")
cat(response)
```

## Single-Agent Graph with `react_graph()`

Why wrap a single agent in a graph at all? Because `react_graph()` adds
three capabilities that a bare agent lacks: **state management** (the graph
maintains a typed state object that persists across iterations),
**checkpointing** (you can save and resume mid-run), and **tracing**
(pass a securetrace `Trace` to automatically instrument every iteration).

Even for simple use cases, the graph wrapper gives you a consistent interface
(`$invoke()`, `$stream()`) that scales from one agent to many without changing
your calling code.

```{r react}
analyst <- agent("analyst", chat = chat_anthropic(
  system_prompt = "You are a data analyst. Analyze data and provide insights."
))

graph <- react_graph(analyst)
result <- graph$invoke(list(messages = list(
  "What are the key relationships in the mtcars dataset?"
)))
```

Use `verbose = TRUE` when compiling to see execution flow. With the
convenience functions, pass `verbose` to `$invoke()`:

```{r react-verbose}
result <- graph$invoke(
  list(messages = list("Describe the distribution of mpg in mtcars.")),
  verbose = TRUE
)
```

## Agent Pipeline with `pipeline_graph()`

When a task decomposes into distinct stages -- profile the data, then analyze
patterns, then write a report -- a pipeline chains agents in sequence. Each
agent processes the shared state and passes it forward. This is simpler and
cheaper than a supervisor because each agent makes exactly one LLM call,
and the execution order is fixed at graph construction time.

```{r pipeline}
profiler <- agent("profiler", chat = chat_anthropic(
  system_prompt = "Profile datasets: describe columns, types, missing values, distributions."
))

analyst <- agent("analyst", chat = chat_anthropic(
  system_prompt = "Given a data profile, identify patterns, correlations, and anomalies."
))

pipeline <- pipeline_graph(profiler, analyst)
result <- pipeline$invoke(list(messages = list(
  "Analyze the mtcars dataset focusing on fuel efficiency factors."
)))
```

## Next Steps

- **[Multi-Agent Workflows](multi-agent.html)** -- pipelines, supervisor routing, and visualization
- **[Secure Execution](securer.html)** -- sandboxed code execution with securer
- **[Traced Workflows](tracing.html)** -- observability with securetrace
- **[Governed Agent](governed-agent.html)** -- the full 7-package stack
